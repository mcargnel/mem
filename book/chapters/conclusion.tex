Este trabajo se propuso abordar el compromiso o \textit{trade-off} entre la capacidad predictiva y la capacidad explicativa. Se partió de la premisa de que, tradicionalmente, se debía elegir entre modelos simples e interpretables, como la regresión lineal, o modelos complejos de alta capacidad predictiva pero difícil interpretación, conocidos como cajas negras o \textit{black boxes}.

A lo largo del desarrollo, se mostró que los ensambles de árboles, específicamente \textit{random forest} y \textit{gradient boosting machines}, representan una buena solución para problemas de predicción, superando consistentemente a los modelos base y a las regresiones lineales en los casos de estudio analizados. Sin embargo, su complejidad inherente planteaba el desafío de la interpretabilidad.

Para superar esta barrera, se estudiaron y aplicaron técnicas de aprendizaje automático interpretable agnósticas al modelo. Se vio que la (\textit{permutation feature importance}) permite identificar qué covariables son fundamentales para el modelo, mientras que los (\textit{partial dependence plots}) e \textit{individual conditional expectation} (ICE) permiten visualizar cómo se relacionan estas variables con la variable dependiente. Además, se abordó el problema de la estabilidad y los \textit{Rashomon Sets}, destacando que la interpretación debe ser cautelosa ante la existencia de múltiples modelos con rendimiento similar pero interpretaciones diferentes.

La aplicación de estas metodologías en conjuntos de datos reales de naturaleza diversa (aerodinámica, ingeniería civil y enología) demostró como llevar a la practica estas tecnicas e interpretar las variables que se incluyeron.

Es fundamental concluir este trabajo remarcando ciertas limitaciones. En primer lugar, la interpretación del modelo no es causal. Las técnicas presentadas, como los gráficos de dependencia parcial, describen cómo el modelo utiliza las variables para predecir, basándose en las relaciones capturadas durante el entrenamiento.

Si bien se discutió teóricamente, siguiendo a \cite{Zhao_2021}, que supuestos como la ausencia de confusores no observados y la correcta especificación del DAG estas interpretaciones pueden tener una lectura causal, en la práctica, y especialmente con datos observacionales, estos supuestos raramente se pueden verificar en su totalidad. Por lo tanto, las conclusiones extraídas de estas herramientas deben entenderse principalmente en términos de asociación y poder predictivo. Para realizar inferencia causal rigurosa, sería necesario complementar estas técnicas con marcos de trabajo específicos, como el \textit{double machine learning} o el diseño experimental adecuado, que exceden el alcance de este estudio.

Otra limitación importante es la falta de una teoría de inferencia formal robusta similar a la que existe para la regresión lineal o la estadística clásica. Mientras que en los modelos lineales tradicionales se cuenta con intervalos de confianza, pruebas de hipótesis y propiedades asintóticas conocidas para los estimadores, en los modelos de aprendizaje automático estas garantías teóricas son mucho más difíciles de establecer. Si bien existen aproximaciones basadas en remuestreo, como el \textit{bootstrapping}, para estimar la varianza y construir intervalos de confianza, estas técnicas suelen carecer del mismo rigor matemático y formalismo que caracteriza a la inferencia estadística clásica. Esto implica que las conclusiones sobre la importancia de una variable o los efectos deben tomarse como direccionales. Sin embargo, es relevante el desarrollo de \textit{Conformal Prediction} \cite{vovk_2005}. Este enfoque permite pasar de predicciones puntuales a intervalos de predicción válidos en muestras finitas. De este modo, se dota a los modelos de caja negra de garantías estadísticas, un avance que ha cobrado gran interés reciente \cite{angelopoulos_2023}.

En definitiva, este trabajo evidencia que el aprendizaje automático interpretable es una herramienta poderosa para dotar de transparencia a los modelos predictivos, permitiendo a los usuarios confiar en sus decisiones, aunque siempre manteniendo una postura crítica respecto a sus limitaciones.